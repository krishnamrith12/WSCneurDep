@inproceedings{platform12,
author =        "Pawan Goyal and G\'erard Huet and Amba Kulkarni and Peter Scharf and Ralph Bunker",
title =         "A Distributed Platform for {Sanskrit} Processing",
booktitle =     "24th International Conference on Computational Linguistics (COLING), Mumbai",
year =          "2012"
}
@BOOK{scharf-hyman09,
author =        "Peter Scharf and Malcolm Hyman",
title =         "Linguistic Issues in Encoding {Sanskrit}",
year =          "2009",
publisher =     "Motilal Banarsidass, Delhi"
}
@article{kubler2009dependency,
  title={Dependency parsing},
  author={K{\"u}bler, Sandra and McDonald, Ryan and Nivre, Joakim},
  journal={Synthesis lectures on human language technologies},
  volume={1},
  number={1},
  pages={1--127},
  year={2009},
  publisher={Morgan \& Claypool Publishers}
}
 
  @inproceedings{kulkarni-2013-deterministic,
    title = "A Deterministic Dependency Parser with Dynamic Programming for {S}anskrit",
    author = "Kulkarni, Amba",
    booktitle = "Proceedings of the Second International Conference on Dependency Linguistics ({D}ep{L}ing 2013)",
    month = aug,
    year = "2013",
    address = "Prague, Czech Republic",
    publisher = "Charles University in Prague, Matfyzpress, Prague, Czech Republic",
    url = "https://www.aclweb.org/anthology/W13-3718",
    pages = "157--166",
}

@inproceedings{mcdonald-etal-2005-online,
    title = "Online Large-Margin Training of Dependency Parsers",
    author = "McDonald, Ryan  and
      Crammer, Koby  and
      Pereira, Fernando",
    booktitle = "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05)",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P05-1012",
    doi = "10.3115/1219840.1219852",
    pages = "91--98",
}




@inproceedings{mcdonald-etal-2005-non,
    title = "Non-Projective Dependency Parsing using Spanning Tree Algorithms",
    author = "McDonald, Ryan  and
      Pereira, Fernando  and
      Ribarov, Kiril  and
      Haji{\v{c}}, Jan",
    booktitle = "Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2005",
    address = "Vancouver, British Columbia, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/H05-1066",
    pages = "523--530",
}


@inproceedings{yamada-matsumoto-2003-statistical,
    title = "Statistical Dependency Analysis with Support Vector Machines",
    author = "Yamada, Hiroyasu  and
      Matsumoto, Yuji",
    booktitle = "Proceedings of the Eighth International Conference on Parsing Technologies",
    month = apr,
    year = "2003",
    address = "Nancy, France",
    url = "https://www.aclweb.org/anthology/W03-3023",
    pages = "195--206",
    abstract = "In this paper, we propose a method for analyzing word-word dependencies using deterministic bottom-up manner using Support Vector machines. We experimented with dependency trees converted from Penn treebank data, and achieved over 90{\%} accuracy of word-word dependency. Though the result is little worse than the most up-to-date phrase structure based parsers, it looks satisfactorily accurate considering that our parser uses no information from phrase structures.",
}


@inproceedings{kudo-matsumoto-2000-japanese,
    title = "{J}apanese Dependency Structure Analysis Based on Support Vector Machines",
    author = "Kudo, Taku  and
      Matsumoto, Yuji",
    booktitle = "2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora",
    month = oct,
    year = "2000",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W00-1303",
    doi = "10.3115/1117794.1117797",
    pages = "18--25",
}


@inproceedings{eisner-1996-three,
    title = "Three New Probabilistic Models for Dependency Parsing: An Exploration",
    author = "Eisner, Jason M.",
    booktitle = "{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics",
    year = "1996",
    url = "https://www.aclweb.org/anthology/C96-1058",
}



@inproceedings{collins-1996-new,
    title = "A New Statistical Parser Based on Bigram Lexical Dependencies",
    author = "Collins, Michael John",
    booktitle = "34th Annual Meeting of the Association for Computational Linguistics",
    month = jun,
    year = "1996",
    address = "Santa Cruz, California, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P96-1025",
    doi = "10.3115/981863.981888",
    pages = "184--191",
}


@inproceedings{zen2,
author =        "G\'erard Huet",
title =         "The {Zen} Computational Linguistics Toolkit:
Lexicon Structures and Morphology Computations using a Modular
Functional Programming Language",
booktitle =     "Tutorial, Language Engineering Conference LEC'2002", 
location =      "Hyderabad",
year =          "2002"
}

@article{mcdonald-nivre-2011-analyzing,
    title = "Analyzing and Integrating Dependency Parsers",
    author = "McDonald, Ryan  and
      Nivre, Joakim",
    journal = "Computational Linguistics",
    volume = "37",
    number = "1",
    year = "2011",
    url = "https://www.aclweb.org/anthology/J11-1007",
    doi = "10.1162/coli_a_00039",
    pages = "197--230",
}



@article{rotman2019deep,
  title={Deep Contextualized Self-training for Low Resource Dependency Parsing},
  author={Rotman, Guy and Reichart, Roi},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={695--713},
  year={2019},
  publisher={MIT Press}
}


@inproceedings{rybak2018semi,
  title={Semi-supervised neural system for tagging, parsing and lematization},
  author={Rybak, Piotr and Wr{\'o}blewska, Alina},
  booktitle={Proceedings of the CoNLL 2018 Shared Task: Multilingual parsing from raw text to universal dependencies},
  pages={45--54},
  year={2018}
}
@inproceedings{clark-etal-2018-semi,
    title = "Semi-Supervised Sequence Modeling with Cross-View Training",
    author = "Clark, Kevin  and
      Luong, Minh-Thang  and
      Manning, Christopher D.  and
      Le, Quoc",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1217",
    doi = "10.18653/v1/D18-1217",
    pages = "1914--1925",
    abstract = "Unsupervised representation learning algorithms such as word2vec and ELMo improve the accuracy of many supervised NLP models, mainly because they can take advantage of large amounts of unlabeled text. However, the supervised models only learn from task-specific labeled data during the main training phase. We therefore propose Cross-View Training (CVT), a semi-supervised learning algorithm that improves the representations of a Bi-LSTM sentence encoder using a mix of labeled and unlabeled data. On labeled examples, standard supervised learning is used. On unlabeled examples, CVT teaches auxiliary prediction modules that see restricted views of the input (e.g., only part of a sentence) to match the predictions of the full model seeing the whole input. Since the auxiliary modules and the full model share intermediate representations, this in turn improves the full model. Moreover, we show that CVT is particularly effective when combined with multi-task learning. We evaluate CVT on five sequence tagging tasks, machine translation, and dependency parsing, achieving state-of-the-art results.",
}
@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}
@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}
@inproceedings{sato-etal-2017-adversarial,
    title = "Adversarial Training for Cross-Domain Universal Dependency Parsing",
    author = "Sato, Motoki  and
      Manabe, Hitoshi  and
      Noji, Hiroshi  and
      Matsumoto, Yuji",
    booktitle = "Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K17-3007",
    doi = "10.18653/v1/K17-3007",
    pages = "71--79",
    abstract = "We describe our submission to the CoNLL 2017 shared task, which exploits the shared common knowledge of a language across different domains via a domain adaptation technique. Our approach is an extension to the recently proposed adversarial training technique for domain adaptation, which we apply on top of a graph-based neural dependency parsing model on bidirectional LSTMs. In our experiments, we find our baseline graph-based parser already outperforms the official baseline model (UDPipe) by a large margin. Further, by applying our technique to the treebanks of the same language with different domains, we observe an additional gain in the performance, in particular for the domains with less training data.",
}
@inproceedings{DBLP:conf/iclr/DozatM17,
  author    = {Timothy Dozat and
               Christopher D. Manning},
  title     = {Deep Biaffine Attention for Neural Dependency Parsing},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=Hk95PK9le},
  timestamp = {Thu, 25 Jul 2019 14:25:56 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DozatM17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{collins2004incremental,
  title={Incremental parsing with the perceptron algorithm},
  author={Collins, Michael and Roark, Brian},
  booktitle={Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics},
  pages={111},
  year={2004},
  organization={Association for Computational Linguistics}
}
@article{daume2009search,
  title={Search-based structured prediction},
  author={Daum{\'e}, Hal and Langford, John and Marcu, Daniel},
  journal={Machine learning},
  volume={75},
  number={3},
  pages={297--325},
  year={2009},
  publisher={Springer}
}

@inproceedings{che-etal-2018-towards,
    title = "Towards Better {UD} Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation",
    author = "Che, Wanxiang  and
      Liu, Yijia  and
      Wang, Yuxuan  and
      Zheng, Bo  and
      Liu, Ting",
    booktitle = "Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K18-2005",
    doi = "10.18653/v1/K18-2005",
    pages = "55--64",
    abstract = "This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. We base our submission on Stanford{'}s winning system for the CoNLL 2017 shared task and make two effective extensions: 1) incorporating deep contextualized word embeddings into both the part of speech tagger and parser; 2) ensembling parsers trained with different initialization. We also explore different ways of concatenating treebanks for further improvements. Experimental results on the development data show the effectiveness of our methods. In the final evaluation, our system was ranked first according to LAS (75.84{\%}) and outperformed the other systems by a large margin.",
}

@InProceedings{	  huet-goyal13,
  author	= {G\'erard Huet and Pawan Goyal},
  title		= {Design of a lean interface for {Sanskrit} corpus
		  annotation},
  booktitle	= {Proceedings of ICON 2013, the 10th International
		  Conference on NLP},
  pages		= {177--186},
  year		= {2013}
}


@inproceedings{nivre-fang-2017-universal,
    title = "Universal Dependency Evaluation",
    author = "Nivre, Joakim  and
      Fang, Chiao-Ting",
    booktitle = "Proceedings of the {N}o{D}a{L}i{D}a 2017 Workshop on Universal Dependencies ({UDW} 2017)",
    month = may,
    year = "2017",
    address = "Gothenburg, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0411",
    pages = "86--95",
}

@article{GIBSON2019389,
title = "How Efficiency Shapes Human Language",
journal = "Trends in Cognitive Sciences",
volume = "23",
number = "5",
pages = "389 - 407",
year = "2019",
issn = "1364-6613",
doi = "https://doi.org/10.1016/j.tics.2019.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S1364661319300580",
author = "Edward Gibson and Richard Futrell and Steven P. Piantadosi and Isabelle Dautriche and Kyle Mahowald and Leon Bergen and Roger Levy",
keywords = "language evolution, communication, language efficiency, cross-linguistic universals, language learnability, language complexity",
abstract = "Cognitive science applies diverse tools and perspectives to study human language. Recently, an exciting body of work has examined linguistic phenomena through the lens of efficiency in usage: what otherwise puzzling features of language find explanation in formal accounts of how language might be optimized for communication and learning? Here, we review studies that deploy formal tools from probability and information theory to understand how and why language works the way that it does, focusing on phenomena ranging from the lexicon through syntax. These studies show how a pervasive pressure for efficiency guides the forms of natural language and indicate that a rich future for language research lies in connecting linguistics to cognitive psychology and mathematical theories of communication and inference."
}

@inproceedings{krishna-etal-2019-poetry,
    title = "Poetry to Prose Conversion in {S}anskrit as a Linearisation Task: A Case for Low-Resource Languages",
    author = "Krishna, Amrith  and
      Sharma, Vishnu  and
      Santra, Bishal  and
      Chakraborty, Aishik  and
      Satuluri, Pavankumar  and
      Goyal, Pawan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1111",
    doi = "10.18653/v1/P19-1111",
    pages = "1160--1166",
    abstract = "The word ordering in a Sanskrit verse is often not aligned with its corresponding prose order. Conversion of the verse to its corresponding prose helps in better comprehension of the construction. Owing to the resource constraints, we formulate this task as a word ordering (linearisation) task. In doing so, we completely ignore the word arrangement at the verse side. k{\=a}vya guru, the approach we propose, essentially consists of a pipeline of two pretraining steps followed by a seq2seq model. The first pretraining step learns task-specific token embeddings from pretrained embeddings. In the next step, we generate multiple possible hypotheses for possible word arrangements of the input {\%}using another pretraining step. We then use them as inputs to a neural seq2seq model for the final prediction. We empirically show that the hypotheses generated by our pretraining step result in predictions that consistently outperform predictions based on the original order in the verse. Overall, k{\=a}vya guru outperforms current state of the art models in linearisation for the poetry to prose conversion task in Sanskrit.",
}


@Article{	  goyal2016design,
  title		= {Design and analysis of a lean interface for Sanskrit
		  corpus annotation},
  author	= {Goyal, Pawan and Huet, Gerard},
  journal	= {Journal of Language Modelling},
  volume	= {4},
  number	= {2},
  pages		= {145--182},
  year		= {2016}
}
@inproceedings{kuhlmann-etal-2011-dynamic,
    title = "Dynamic Programming Algorithms for Transition-Based Dependency Parsers",
    author = "Kuhlmann, Marco  and
      G{\'o}mez-Rodr{\'\i}guez, Carlos  and
      Satta, Giorgio",
    booktitle = "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2011",
    address = "Portland, Oregon, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P11-1068",
    pages = "673--682",
}


@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}
@inproceedings{credit_asg,
author = {Chang, Kai-Wei and He, He and Daum\'{e}, Hal and Langford, John and Ross, Stephane},
title = {A Credit Assignment Compiler for Joint Prediction},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {1713–1721},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS’16}
}
@article{chang2015learning,
  title={Learning to search for dependencies},
  author={Chang, Kai-Wei and He, He and Daum{\'e} III, Hal and Langford, John},
  journal={arXiv preprint arXiv:1503.05615},
  year={2015}
}
@article{Daum2014EfficientPL,
  title={Efficient programmable learning to search},
  author={Hal Daum{\'e} and John Langford and St{\'e}phane Ross},
  journal={ArXiv},
  year={2014},
  volume={abs/1406.1837}
}
@article{kiperwasser-goldberg-2016-simple,
    title = "Simple and Accurate Dependency Parsing Using Bidirectional {LSTM} Feature Representations",
    author = "Kiperwasser, Eliyahu  and
      Goldberg, Yoav",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "4",
    year = "2016",
    url = "https://www.aclweb.org/anthology/Q16-1023",
    doi = "10.1162/tacl_a_00101",
    pages = "313--327",
    abstract = "We present a simple and effective scheme for dependency parsing which is based on bidirectional-LSTMs (BiLSTMs). Each sentence token is associated with a BiLSTM vector representing the token in its sentential context, and feature vectors are constructed by concatenating a few BiLSTM vectors. The BiLSTM is trained jointly with the parser objective, resulting in very effective feature extractors for parsing. We demonstrate the effectiveness of the approach by applying it to a greedy transition-based parser as well as to a globally optimized graph-based parser. The resulting parsers have very simple architectures, and match or surpass the state-of-the-art accuracies on English and Chinese.",
}
@article{edmonds1967optimum,
  title={Optimum branchings},
  author={Edmonds, Jack},
  journal={Journal of Research of the national Bureau of Standards B},
  volume={71},
  number={4},
  pages={233--240},
  year={1967}
}

@inproceedings{mcdonald-pereira-2006-online,
    title = "Online Learning of Approximate Dependency Parsing Algorithms",
    author = "McDonald, Ryan  and
      Pereira, Fernando",
    booktitle = "11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2006",
    address = "Trento, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E06-1011",
}


@article{edmonds1971matroids,
  title={Matroids and the greedy algorithm},
  author={Edmonds, Jack},
  journal={Mathematical programming},
  volume={1},
  number={1},
  pages={127--136},
  year={1971},
  publisher={Springer}
}



@inproceedings{buchholz-marsi-2006-conll,
    title = "{C}o{NLL}-X Shared Task on Multilingual Dependency Parsing",
    author = "Buchholz, Sabine  and
      Marsi, Erwin",
    booktitle = "Proceedings of the Tenth Conference on Computational Natural Language Learning ({C}o{NLL}-X)",
    month = jun,
    year = "2006",
    address = "New York City",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W06-2920",
    pages = "149--164",
}

@article{goldberg2013training,
  title={Training deterministic parsers with non-deterministic oracles},
  author={Goldberg, Yoav and Nivre, Joakim},
  journal={Transactions of the association for Computational Linguistics},
  volume={1},
  pages={403--414},
  year={2013},
  publisher={MIT Press}
}
@inproceedings{dozat2017stanford,
  title={Stanford’s graph-based neural dependency parser at the conll 2017 shared task},
  author={Dozat, Timothy and Qi, Peng and Manning, Christopher D},
  booktitle={Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
  pages={20--30},
  year={2017}
}


@inproceedings{tiedemann-2015-cross,
    title = "Cross-Lingual Dependency Parsing with Universal Dependencies and Predicted {P}o{S} Labels",
    author = {Tiedemann, J{\"o}rg},
    booktitle = "Proceedings of the Third International Conference on Dependency Linguistics (Depling 2015)",
    month = aug,
    year = "2015",
    address = "Uppsala, Sweden",
    publisher = "Uppsala University, Uppsala, Sweden",
    url = "https://www.aclweb.org/anthology/W15-2137",
    pages = "340--349",
}
@inproceedings{mcdonald-satta-2007-complexity,
    title = "On the Complexity of Non-Projective Data-Driven Dependency Parsing",
    author = "McDonald, Ryan  and
      Satta, Giorgio",
    booktitle = "Proceedings of the Tenth International Conference on Parsing Technologies",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W07-2216",
    pages = "121--132",
}
@inproceedings{begum-etal-2008-dependency,
    title = "Dependency Annotation Scheme for {I}ndian Languages",
    author = "Begum, Rafiya  and
      Husain, Samar  and
      Dhwaj, Arun  and
      Sharma, Dipti Misra  and
      Bai, Lakshmi  and
      Sangal, Rajeev",
    booktitle = "Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II}",
    year = "2008",
    url = "https://www.aclweb.org/anthology/I08-2099",
}

@article{mrini2019rethinking,
  title={Rethinking Self-Attention: An Interpretable Self-Attentive Encoder-Decoder Parser},
  author={Mrini, Khalil and Dernoncourt, Franck and Bui, Trung and Chang, Walter and Nakashole, Ndapa},
  journal={arXiv preprint arXiv:1911.03875},
  year={2019}
}

    @manual{madUrl,
      title  = "Mean absolute deviation (MAD) review",
      author = "Khan-Academy",
      url    = "https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data/other-measures-of-spread/a/mean-absolute-deviation-mad-review",
      year = "accessed 15 Apr 2020"
     
    }


@inproceedings{wang-etal-2018-improved,
    title = "Improved Dependency Parsing using Implicit Word Connections Learned from Unlabeled Data",
    author = "Wang, Wenhui  and
      Chang, Baobao  and
      Mansur, Mairgup",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1311",
    doi = "10.18653/v1/D18-1311",
    pages = "2857--2863",
    abstract = "Pre-trained word embeddings and language model have been shown useful in a lot of tasks. However, both of them cannot directly capture word connections in a sentence, which is important for dependency parsing given its goal is to establish dependency relations between words. In this paper, we propose to implicitly capture word connections from unlabeled data by a word ordering model with self-attention mechanism. Experiments show that these implicit word connections do improve our parsing model. Furthermore, by combining with a pre-trained language model, our model gets state-of-the-art performance on the English PTB dataset, achieving 96.35{\%} UAS and 95.25{\%} LAS.",
}


@inproceedings{qi-etal-2018-universal,
    title = "Universal Dependency Parsing from Scratch",
    author = "Qi, Peng  and
      Dozat, Timothy  and
      Zhang, Yuhao  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K18-2016",
    doi = "10.18653/v1/K18-2016",
    pages = "160--170",
    abstract = "This paper describes Stanford{'}s system at the CoNLL 2018 UD Shared Task. We introduce a complete neural pipeline system that takes raw text as input, and performs all tasks required by the shared task, ranging from tokenization and sentence segmentation, to POS tagging and dependency parsing. Our single system submission achieved very competitive performance on big treebanks. Moreover, after fixing an unfortunate bug, our corrected system would have placed the 2nd, 1st, and 3rd on the official evaluation metrics LAS, MLAS, and BLEX, and would have outperformed all submission systems on low-resource treebank categories on all metrics by a large margin. We further show the effectiveness of different model components through extensive ablation studies.",
}




@inproceedings{kulkarni-etal-2019-dependency,
    title = "Dependency Parser for {S}anskrit Verses",
    author = "Kulkarni, Amba  and
      Vikram, Sanal  and
      K, Sriram",
    booktitle = "Proceedings of the 6th International Sanskrit Computational Linguistics Symposium",
    month = oct,
    year = "2019",
    address = "IIT Kharagpur, India",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-7502",
    pages = "14--27",
}


@InProceedings{	  Ambakulkarni2015,
  author	= {Amba Kulkarni and Preethi Shukla and Pavankumar Satuluri
		  and Devanand Shukl},
  title		= {How {F}ree is ‘free’ {W}ord {O}rder in {S}anskrit},
  booktitle	= {The {S}anskrit {L}ibrary, USA},
  year		= {2015},
  pages		= {269-304},
  url		= {https://goo.gl/7GnXuS}
}

@InProceedings{pmlr-v37-changb15searchteacher,
  title = 	 {Learning to Search Better than Your Teacher},
  author = 	 {Kai-Wei Chang and Akshay Krishnamurthy and Alekh Agarwal and Hal Daume and John Langford},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2058--2066},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/changb15.pdf},
  url = 	 {http://proceedings.mlr.press/v37/changb15.html},
  abstract = 	 {Methods for learning to search for structured prediction typically imitate a reference policy, with existing theoretical guarantees demonstrating low regret compared to that reference. This is unsatisfactory in many applications where the reference policy is suboptimal and the goal of learning is to improve upon it. Can learning to search work even when the reference is poor? We provide a new learning to search algorithm, LOLS, which does well relative to the reference policy, but additionally guarantees low regret compared to deviations from the learned policy: a local-optimality guarantee. Consequently, LOLS can improve upon the reference policy, unlike previous algorithms. This enables us to develop structured contextual bandits, a partial information structured prediction setting with many potential applications.}
}

@inproceedings{zhang-nivre-2011-transition,
    title = "Transition-based Dependency Parsing with Rich Non-local Features",
    author = "Zhang, Yue  and
      Nivre, Joakim",
    booktitle = "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2011",
    address = "Portland, Oregon, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P11-2033",
    pages = "188--193",
}
@inproceedings{collins-roark-2004-incremental,
    title = "Incremental Parsing with the Perceptron Algorithm",
    author = "Collins, Michael  and
      Roark, Brian",
    booktitle = "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04)",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    url = "https://www.aclweb.org/anthology/P04-1015",
    doi = "10.3115/1218955.1218970",
    pages = "111--118",
}


@article{zhang-clark-2011-syntactic,
    title = "Syntactic Processing Using the Generalized Perceptron and Beam Search",
    author = "Zhang, Yue  and
      Clark, Stephen",
    journal = "Computational Linguistics",
    volume = "37",
    number = "1",
    year = "2011",
    url = "https://www.aclweb.org/anthology/J11-1005",
    doi = "10.1162/coli_a_00037",
    pages = "105--151",
}


@InProceedings{kulkarni10dep,
author="Kulkarni, Amba
and Pokar, Sheetal
and Shukl, Devanand",
editor="Jha, Girish Nath",
title="Designing a Constraint Based Parser for Sanskrit",
booktitle="Sanskrit Computational Linguistics",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="70--90",
abstract="Verbal understanding ({\'{s}}{\={a}}bdabodha) of any utterance requires the knowledge of how words in that utterance are related to each other. Such knowledge is usually available in the form of cognition of grammatical relations. Generative grammars describe how a language codes these relations. Thus the knowledge of what information various grammatical relations convey is available from the generation point of view and not the analysis point of view. In order to develop a parser based on any grammar one should then know precisely the semantic content of the grammatical relations expressed in a language string, the clues for extracting these relations and finally whether these relations are expressed explicitly or implicitly. Based on the design principles that emerge from this knowledge, we model the parser as finding a directed Tree, given a graph with nodes representing the words and edges representing the possible relations between them. Further, we also use the M{\={\i}}m{\={a}}ṃs{\={a}} constraint of {\={a}}k{\={a}}ṅkṣ{\={a}} (expectancy) to rule out non-solutions and sannidhi (proximity) to prioritize the solutions. We have implemented a parser based on these principles and its performance was found to be satisfactory giving us a confidence to extend its functionality to handle the complex sentences.",
isbn="978-3-642-17528-2"
}



@InProceedings{sabdabodharamakrishna,
author="Ramkrishnamacharyulu, K. V.",
editor="Kulkarni, Amba
and Huet, G{\'e}rard",
title="Annotating Sanskrit Texts Based on {\'{S}}{\={a}}bdabodha Systems",
booktitle="Sanskrit Computational Linguistics",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="26--39",
abstract="Though Sanskrit has a huge repository of texts as well as well discussed grammar formalism, we still neither have a full fledged parser for Sanskrit based on this formalism nor do we have any annotated text.",
isbn="978-3-540-93885-9"
}



@inproceedings{tandon-sharma-2017-unity,
    title = "Unity in Diversity: A Unified Parsing Strategy for Major {I}ndian Languages",
    author = "Tandon, Juhi  and
      Sharma, Dipti Misra",
    booktitle = "Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017)",
    month = sep,
    year = "2017",
    address = "Pisa,Italy",
    publisher = {Link{\"o}ping University Electronic Press},
    url = "https://www.aclweb.org/anthology/W17-6529",
    pages = "255--265",
}

@article{bharati1991computational,
  title={A Computational Grammar for Indian languages processing},
  author={Bharati, Akshar and Chaitanya, Vineet and Sangal, Rajeev},
  journal={Indian Linguistics Journal},
  volume={52},
  pages={91--103},
  year={1991}
}


  @article{seeker-cetinoglu-2015-graph,
    title = "A Graph-based Lattice Dependency Parser for Joint Morphological Segmentation and Syntactic Analysis",
    author = {Seeker, Wolfgang  and
      {\c{C}}etino{\u{g}}lu, {\"O}zlem},
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "3",
    year = "2015",
    url = "https://www.aclweb.org/anthology/Q15-1026",
    doi = "10.1162/tacl_a_00144",
    pages = "359--373",
    abstract = "Space-delimited words in Turkish and Hebrew text can be further segmented into meaningful units, but syntactic and semantic context is necessary to predict segmentation. At the same time, predicting correct syntactic structures relies on correct segmentation. We present a graph-based lattice dependency parser that operates on morphological lattices to represent different segmentations and morphological analyses for a given input sentence. The lattice parser predicts a dependency tree over a path in the lattice and thus solves the joint task of segmentation, morphological analysis, and syntactic parsing. We conduct experiments on the Turkish and the Hebrew treebank and show that the joint model outperforms three state-of-the-art pipeline systems on both data sets. Our work corroborates findings from constituency lattice parsing for Hebrew and presents the first results for full lattice parsing on Turkish.",
}


@inproceedings{weiss-etal-2015-structured,
    title = "Structured Training for Neural Network Transition-Based Parsing",
    author = "Weiss, David  and
      Alberti, Chris  and
      Collins, Michael  and
      Petrov, Slav",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P15-1032",
    doi = "10.3115/v1/P15-1032",
    pages = "323--333",
}



@inproceedings{chen-manning-2014-fast,
    title = "A Fast and Accurate Dependency Parser using Neural Networks",
    author = "Chen, Danqi  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1082",
    doi = "10.3115/v1/D14-1082",
    pages = "740--750",
}



@INPROCEEDINGS{Attardi+al-2009,
     author = {Attardi, Giuseppe and Dell'Orletta, Felice and Simi, Maria and Turian, Joseph},
   keywords = {classifier, dependency parsing, natural language, parser, perceptron},
      title = {Accurate Dependency Parsing with a Stacked Multilayer Perceptron},
  booktitle = {Proceeding of Evalita 2009},
     series = {LNCS},
       year = {2009},
  publisher = {Springer},
   abstract = {Abstract. DeSR is a statistical transition-based dependency parser which learns from annotated corpora which actions to perform for building parse trees while scanning a sentence. We describe recent improvements to the parser, in particular stacked parsing, exploiting a beam search strategy and using a Multilayer Perceptron classifier. For the Evalita 2009 Dependency Parsing task DesR was configured to use a combination of stacked parsers. The stacked combination achieved the best accuracy scores in both the main and pilot subtasks. The contribution to the result of various choices is analyzed, in particular for taking advantage of the peculiar features of the TUT Treebank.}
}


@inproceedings{titov-henderson-2007-latent,
    title = "A Latent Variable Model for Generative Dependency Parsing",
    author = "Titov, Ivan  and
      Henderson, James",
    booktitle = "Proceedings of the Tenth International Conference on Parsing Technologies",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W07-2218",
    pages = "144--155",
}


@book{10.5555/578789Ullman,
author = {Aho, Alfred V. and Ullman, Jeffrey D.},
title = {The Theory of Parsing, Translation, and Compiling},
year = {1972},
isbn = {0139145567},
publisher = {Prentice-Hall, Inc.},
address = {USA}
}

@inproceedings{zhang-mcdonald-2014-enforcing,
    title = "Enforcing Structural Diversity in Cube-pruned Dependency Parsing",
    author = "Zhang, Hao  and
      McDonald, Ryan",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P14-2107",
    doi = "10.3115/v1/P14-2107",
    pages = "656--661",
}





@inproceedings{martins-etal-2010-turbo,
    title = "Turbo Parsers: Dependency Parsing by Approximate Variational Inference",
    author = "Martins, Andr{\'e}  and
      Smith, Noah  and
      Xing, Eric  and
      Aguiar, Pedro  and
      Figueiredo, M{\'a}rio",
    booktitle = "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2010",
    address = "Cambridge, MA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D10-1004",
    pages = "34--44",
}

@inproceedings{martins-etal-2009-concise,
    title = "Concise Integer Linear Programming Formulations for Dependency Parsing",
    author = "Martins, Andr{\'e}  and
      Smith, Noah  and
      Xing, Eric",
    booktitle = "Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP}",
    month = aug,
    year = "2009",
    address = "Suntec, Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P09-1039",
    pages = "342--350",
}



@inproceedings{carreras-2007-experiments,
    title = "Experiments with a Higher-Order Projective Dependency Parser",
    author = "Carreras, Xavier",
    booktitle = "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL})",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D07-1101",
    pages = "957--961",
}
@inproceedings{koo-collins-2010-efficient,
    title = "Efficient Third-Order Dependency Parsers",
    author = "Koo, Terry  and
      Collins, Michael",
    booktitle = "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P10-1001",
    pages = "1--11",
}


@inproceedings{mcdonald-etal-2013-universal,
    title = "Universal Dependency Annotation for Multilingual Parsing",
    author = {McDonald, Ryan  and
      Nivre, Joakim  and
      Quirmbach-Brundage, Yvonne  and
      Goldberg, Yoav  and
      Das, Dipanjan  and
      Ganchev, Kuzman  and
      Hall, Keith  and
      Petrov, Slav  and
      Zhang, Hao  and
      T{\"a}ckstr{\"o}m, Oscar  and
      Bedini, Claudia  and
      Bertomeu Castell{\'o}, N{\'u}ria  and
      Lee, Jungmee},
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P13-2017",
    pages = "92--97",
}

@article{selftrainingdep,
author = {Rotman, Guy and Reichart, Roi},
title = {Deep Contextualized Self-training for Low Resource Dependency                     Parsing},
journal = {Transactions of the Association for Computational Linguistics},
volume = {7},
number = {},
pages = {695-713},
year = {2019},
doi = {10.1162/tacl\_a\_00294},

URL = { 
        https://doi.org/10.1162/tacl_a_00294
    
},
eprint = { 
        https://doi.org/10.1162/tacl_a_00294
    
}
,
    abstract = { Neural dependency parsing has proven very effective, achieving state-of-the-art results on numerous domains and languages. Unfortunately, it requires large amounts of labeled data, which is costly and laborious to create. In this paper we propose a self-training algorithm that alleviates this annotation bottleneck by training a parser on its own output. Our Deep Contextualized Self-training (DCST) algorithm utilizes representation models trained on sequence labeling tasks that are derived from the parser’s output when applied to unlabeled data, and integrates these models with the base parser through a gating mechanism. We conduct experiments across multiple languages, both in low resource in-domain and in cross-domain setups, and demonstrate that DCST substantially outperforms traditional self-training as well as recent semi-supervised training methods.1 }
}


@inproceedings{kulmizev-etal-2019-deep,
    title = "Deep Contextualized Word Embeddings in Transition-Based and Graph-Based Dependency Parsing - A Tale of Two Parsers Revisited",
    author = "Kulmizev, Artur  and
      de Lhoneux, Miryam  and
      Gontrum, Johannes  and
      Fano, Elena  and
      Nivre, Joakim",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1277",
    doi = "10.18653/v1/D19-1277",
    pages = "2755--2768",
    abstract = "Transition-based and graph-based dependency parsers have previously been shown to have complementary strengths and weaknesses: transition-based parsers exploit rich structural features but suffer from error propagation, while graph-based parsers benefit from global optimization but have restricted feature scope. In this paper, we show that, even though some details of the picture have changed after the switch to neural networks and continuous representations, the basic trade-off between rich features and global optimization remains essentially the same. Moreover, we show that deep contextualized word embeddings, which allow parsers to pack information about global sentence structure into local feature representations, benefit transition-based parsers more than graph-based parsers, making the two approaches virtually equivalent in terms of both accuracy and error profile. We argue that the reason is that these representations help prevent search errors and thereby allow transition-based parsers to better exploit their inherent strength of making accurate local decisions. We support this explanation by an error analysis of parsing experiments on 13 languages.",
}

@inproceedings{wiseman-rush-2016-sequence,
    title = "Sequence-to-Sequence Learning as Beam-Search Optimization",
    author = "Wiseman, Sam  and
      Rush, Alexander M.",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D16-1137",
    doi = "10.18653/v1/D16-1137",
    pages = "1296--1306",
}


@inproceedings{nivre-2006-constraints,
    title = "Constraints on Non-Projective Dependency Parsing",
    author = "Nivre, Joakim",
    booktitle = "11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2006",
    address = "Trento, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E06-1010",
}


@phdthesis{krishnaThesis,
 author = {Krishna,Amrith},
 title = {Addressing Language Specific Characteristics for Data-Driven Modelling of Lexical, Syntactic and Prosodic Tasks in Sanskrit},
 year = {2019},
 school = {IIT  Kharagpur},
 publisher = {IIT Kharagpur},
 address = {Kharagpur, West Bengal, India},
} 

@inproceedings{mcdonald-nivre-2007-characterizing,
    title = "Characterizing the Errors of Data-Driven Dependency Parsing Models",
    author = "McDonald, Ryan  and
      Nivre, Joakim",
    booktitle = "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL})",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D07-1013",
    pages = "122--131",
}



@article{more-etal-2019-joint,
    title = "Joint Transition-Based Models for Morpho-Syntactic Parsing: Parsing Strategies for {MRL}s and a Case Study from Modern {H}ebrew",
    author = "More, Amir  and
      Seker, Amit  and
      Basmova, Victoria  and
      Tsarfaty, Reut",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    month = mar,
    year = "2019",
    url = "https://www.aclweb.org/anthology/Q19-1003",
    doi = "10.1162/tacl_a_00253",
    pages = "33--48",
    abstract = "In standard NLP pipelines, morphological analysis and disambiguation (MA{\&}D) precedes syntactic and semantic downstream tasks. However, for languages with complex and ambiguous word-internal structure, known as morphologically rich languages (MRLs), it has been hypothesized that syntactic context may be crucial for accurate MA{\&}D, and vice versa. In this work we empirically confirm this hypothesis for Modern Hebrew, an MRL with complex morphology and severe word-level ambiguity, in a novel transition-based framework. Specifically, we propose a joint morphosyntactic transition-based framework which formally unifies two distinct transition systems, morphological and syntactic, into a single transition-based system with joint training and joint inference. We empirically show that MA{\&}D results obtained in the joint settings outperform MA{\&}D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.",
}


@inproceedings{li-etal-2019-semi-supervised,
    title = "Semi-supervised Domain Adaptation for Dependency Parsing",
    author = "Li, Zhenghua  and
      Peng, Xue  and
      Zhang, Min  and
      Wang, Rui  and
      Si, Luo",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1229",
    doi = "10.18653/v1/P19-1229",
    pages = "2386--2395",
    abstract = "During the past decades, due to the lack of sufficient labeled data, most studies on cross-domain parsing focus on unsupervised domain adaptation, assuming there is no target-domain training data. However, unsupervised approaches make limited progress so far due to the intrinsic difficulty of both domain adaptation and parsing. This paper tackles the semi-supervised domain adaptation problem for Chinese dependency parsing, based on two newly-annotated large-scale domain-aware datasets. We propose a simple domain embedding approach to merge the source- and target-domain training data, which is shown to be more effective than both direct corpus concatenation and multi-task learning. In order to utilize unlabeled target-domain data, we employ the recent contextualized word representations and show that a simple fine-tuning procedure can further boost cross-domain parsing accuracy by large margin.",
}
